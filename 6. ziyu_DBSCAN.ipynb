{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "eps = 0.5#0.05\n",
    "min_samples = 4\n",
    "data = np.array([[0, 0, 2], [1, 0, 0], [0, 0, 1], [0, 0, 1.4], [0, 0, 1.5], [0, 0, 1.6]])\n",
    "neighbors_model = NearestNeighbors(n_neighbors=min_samples,radius=eps)\n",
    "neighbors_model.fit(data)\n",
    "distance_matric, idx = neighbors_model.kneighbors([[0, 0, 1.3]], return_distance=True)\n",
    "print(distance_matric)\n",
    "print(idx)\n",
    "data[idx[distance_matric<eps]]\n",
    "# idx[distance_matric>eps]\n",
    "# This has worst case O(n^2) memory complexity\n",
    "# neighborhoods = neighbors_model.radius_neighbors(data, return_distance=False)\n",
    "# neighborhoods\n",
    "# neighborhoods[1][0]\n",
    "# np.array([len(neighbors) for neighbors in neighborhoods])\n",
    "# A list of all core samples found.\n",
    "#         core_samples = np.asarray(n_neighbors >= self.min_samples,\n",
    "#                                   dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import laspy\n",
    "import cv2\n",
    "from TronGisPy import GisIO, CRS, Normalizer, Interpolation\n",
    "import CSF \n",
    "import os, sys, gc, subprocess # file system package\n",
    "import pickle, json, shutil, itertools # file processing basic package\n",
    "import laspy, PySaga, gdal # geo package\n",
    "#import cv2 # open computer vision package\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numba\n",
    "from scipy.stats import entropy\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from sklearn.metrics.pairwise import euclidean_distances, pairwise_distances, pairwise_distances_argmin\n",
    "from util.las import *\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.ndimage.measurements import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "las_fp = \"./data/123.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with laspy.file.File(las_fp, mode = \"r\") as lasFile:\n",
    "    xs, ys, zs = lasFile.x, lasFile.y, lasFile.z\n",
    "    intensities, classifications = lasFile.intensity.copy(), lasFile.Classification.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨便給點\n",
    "x,y,z = (296087.44,2772992.78,23.76) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.96087445e+05, 2.77299278e+06, 2.37652497e+01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reduce_area_x = (xs > x-1) & (xs < x+1)\n",
    "reduce_area_y = (ys > y-1) & (ys < y+1)\n",
    "reduce_area_z = (zs > z-1) & (zs < z+1)\n",
    "xyz = np.array([xs, ys, zs]).T\n",
    "reduce_area = reduce_area_x & reduce_area_y & reduce_area_z\n",
    "data = np.array([xs[reduce_area], ys[reduce_area], zs[reduce_area]]).T\n",
    "neighbors_model = NearestNeighbors()\n",
    "neighbors_model.fit(data)\n",
    "idx = neighbors_model.kneighbors([[x, y, z]], return_distance=False)\n",
    "x_condi = (xs == data[idx[0][0],0])\n",
    "y_condi = (ys == data[idx[0][0],1])\n",
    "z_condi = (zs == data[idx[0][0],2])\n",
    "init_pt = xyz[np.argwhere(x_condi&y_condi&z_condi)[0][0],:]\n",
    "init_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.96087445e+05, 2.77299278e+06, 2.37652497e+01],\n",
       "       [2.96087432e+05, 2.77299279e+06, 2.37517497e+01],\n",
       "       [2.96087461e+05, 2.77299278e+06, 2.37804997e+01],\n",
       "       [2.96087423e+05, 2.77299279e+06, 2.37784997e+01],\n",
       "       [2.96087471e+05, 2.77299278e+06, 2.37514997e+01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "eps = 0.1#0.05\n",
    "min_samples = 10\n",
    "neighbors_model = NearestNeighbors(radius=eps, algorithm='kd_tree')\n",
    "neighbors_model.fit(xyz)\n",
    "\n",
    "visited_pts_idx = []\n",
    "distance_matric, idx = neighbors_model.kneighbors([init_pt], return_distance=True)\n",
    "pts_idx = list(idx)\n",
    "xyz[idx[distance_matric<eps]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.96087456e+05, 2.77299278e+06, 2.37377497e+01],\n",
       "       [2.96087445e+05, 2.77299278e+06, 2.37652497e+01],\n",
       "       [2.96087406e+05, 2.77299279e+06, 2.37624997e+01],\n",
       "       [2.96087432e+05, 2.77299279e+06, 2.37517497e+01],\n",
       "       [2.96087461e+05, 2.77299278e+06, 2.37804997e+01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp == xyz[idx[distance_matric<eps]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RangeQuery(X, Q, eps):\n",
    "    neighbors = list()\n",
    "    for pt in xyz:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_pts_idx = []\n",
    "distance_matric, idx = neighbors_model.kneighbors([init_pt], return_distance=True)\n",
    "pts_idx = list(idx)\n",
    "# print(distance_matric)\n",
    "# print(idx)\n",
    "xyz[idx[distance_matric<eps]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[distance_matric<eps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz[14966635,:]\n",
    "neighbors_model.kneighbors([xyz[14966635,:]], return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epsilon: 2.00  Min_Pts: 2\n",
      "\n",
      "Creating new cluster 0\n",
      "[1, 1]\n",
      "Added points [1.5, 1]\n",
      "[1.8, 1.5]\n",
      "[2.1, 1]\n",
      "[1, 1]\n",
      "[3.1, 2]\n",
      "[4.1, 2]\n",
      "[5.1, 2\n",
      "\n",
      "========== Results of Clustering =============\n",
      "Numbers of all points: 15\n",
      "\n",
      "--------Noises  -1---------\n",
      "\n",
      "--------Cluster 0---------\n",
      "[1, 1]\n",
      "[1.5, 1]\n",
      "[1.8, 1.5]\n",
      "[2.1, 1]\n",
      "[1, 1]\n",
      "[3.1, 2]\n",
      "[4.1, 2]\n",
      "[5.1, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Point(object):\n",
    "    ''' internal helper class to support algorithm implementation'''\n",
    "    def __init__(self,feature_vector):\n",
    "        # feature vector should be something like a list or a numpy\n",
    "        # array\n",
    "        self.feature_vector = feature_vector\n",
    "        self.cluster = None\n",
    "        self.visited = False\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.feature_vector)\n",
    "\n",
    "def _as_points(points):\n",
    "    ''' convert a list of list- or array-type objects to internal\n",
    "    Point class'''\n",
    "    return [Point(point) for point in points]\n",
    "\n",
    "def as_lists(clusters):\n",
    "    ''' converts the Points in each cluster back into regular feature\n",
    "    vectors (lists).'''\n",
    "    clusters_as_points = {}\n",
    "    for cluster, members in clusters.items():\n",
    "        clusters_as_points[cluster] = [member.feature_vector for member in members]\n",
    "    return clusters_as_points\n",
    "\n",
    "def print_points(points):\n",
    "    ''' a wierd klugey function for printing lists of points. ''' \n",
    "    s = ''\n",
    "    for p in points:\n",
    "        s += str(p) + '\\n'\n",
    "    return s[:-2]\n",
    "\n",
    "def euclidean(x,y):\n",
    "    ''' calculate the euclidean distance between x and y.'''\n",
    "    # np.sqrt((x0-y0)^2 + ... (xN-yN)^2)\n",
    "    assert len(x) == len(y)\n",
    "    sum = 0.0\n",
    "    for i in range(len(x)):\n",
    "        sum += np.power(x[i] - y[i],2)\n",
    "    return np.sqrt(sum)\n",
    "\n",
    "def immediate_neighbours(point, all_points, epsilon, distance, debug):\n",
    "    ''' find the immediate neighbours of point.'''\n",
    "    # XXX TODO: this is probably a stupid way to do it; if we could\n",
    "    # use a grid approach it should make this much faster.\n",
    "    neighbours = []\n",
    "    for p in all_points:\n",
    "        if p == point:\n",
    "            # you cant be your own neighbour...!\n",
    "            continue\n",
    "        d = distance(point.feature_vector,p.feature_vector)\n",
    "        if d < epsilon:\n",
    "            neighbours.append(p)\n",
    "    return neighbours\n",
    "\n",
    "def add_connected(points, all_points, epsilon, min_pts, current_cluster, distance, debug):\n",
    "        ''' find every point in the set of all_points which are\n",
    "        density-connected, starting with the initial points list. '''\n",
    "        cluster_points = []\n",
    "        for point in points:\n",
    "            if not point.visited:\n",
    "                point.visited = True\n",
    "                new_points = immediate_neighbours(point, all_points, epsilon, distance, debug)\n",
    "                if len(new_points) >= min_pts:                                \n",
    "                    # append any new points on the end of the list we're\n",
    "                    # already iterating over.\n",
    "                    for p in new_points:\n",
    "                        if p not in points:\n",
    "                            points.append(p)\n",
    "\n",
    "            # here, we separate 'visited' from cluster membership, since\n",
    "            # 'visited' only helps keep track of if we've checked this\n",
    "            # point for neighbours. it may or may not have been assessed\n",
    "            # for cluster membership at that point.\n",
    "            if not point.cluster:\n",
    "                cluster_points.append(point)\n",
    "                point.cluster = current_cluster\n",
    "        if debug: \n",
    "            print('Added points %s' % print_points(cluster_points))\n",
    "        return cluster_points\n",
    "\n",
    "def dbscan(points, epsilon, min_pts, distance=euclidean, debug=False):\n",
    "    assert isinstance(points, list)\n",
    "    epsilon = float(epsilon)\n",
    "    if not isinstance(points[0], Point):\n",
    "        # only check the first list instance. imperfect, but the lists\n",
    "        # could be arbitrarily long.\n",
    "        points = _as_points(points)\n",
    "\n",
    "    if debug:\n",
    "        print('\\nEpsilon: %.2f  Min_Pts: %d' % (epsilon, min_pts))\n",
    "\n",
    "    clusters = {}     # each cluster is a list of points\n",
    "    clusters[-1] = [] # store all the points deemed noise here. \n",
    "    current_cluster = -1\n",
    "    for point in points:\n",
    "        if not point.visited:\n",
    "            point.visited = True\n",
    "            neighbours = immediate_neighbours(point, points, epsilon, distance, debug)\n",
    "            if len(neighbours) >= min_pts:\n",
    "                current_cluster += 1\n",
    "                if debug: \n",
    "                    print('\\nCreating new cluster %d' % (current_cluster))\n",
    "                    print('%s' % str(point))\n",
    "                point.cluster = current_cluster                \n",
    "                cluster = [point,]\n",
    "                cluster.extend(add_connected(neighbours, points, epsilon, min_pts, \n",
    "                                             current_cluster, distance, debug))\n",
    "                clusters[current_cluster] = cluster\n",
    "                break\n",
    "            else:\n",
    "                clusters[-1].append(point)\n",
    "                if debug: \n",
    "                    print('\\nPoint %s has no density-connected neighbours.' % str(point.feature_vector))\n",
    "\n",
    "    # return the dictionary of clusters, converting the Point objects\n",
    "    # in the clusters back to regular lists\n",
    "    return as_lists(clusters)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import random\n",
    "\n",
    "    epsilon = 2.0\n",
    "    min_pts = 2.0\n",
    "    points = []\n",
    "    points.append([1,1])\n",
    "    points.append([1.5,1])\n",
    "    points.append([1.8,1.5])\n",
    "    points.append([2.1,1])\n",
    "    points.append([3.1,2])\n",
    "    points.append([4.1,2])\n",
    "    points.append([5.1,2])\n",
    "    points.append([10,10])\n",
    "    points.append([11,10.5])\n",
    "    points.append([9.5,11])\n",
    "    points.append([9.9,11.4])\n",
    "    points.append([15.0, 17.0])\n",
    "    points.append([15.0, 17.0])\n",
    "    points.append([7.5, -5.0])\n",
    "    points.append([57.5, -55.0])\n",
    "    clusters = dbscan(points, epsilon, min_pts, debug=True)\n",
    "    print('\\n========== Results of Clustering =============')\n",
    "    print(\"Numbers of all points: %d\" % len(points))\n",
    "    for cluster, members in clusters.items():\n",
    "        if cluster == -1:\n",
    "            print('\\n--------Noises  %d---------' % cluster)\n",
    "        else:\n",
    "            print('\\n--------Cluster %d---------' % cluster)\n",
    "        for point in members:\n",
    "            print(point)\n",
    "\n",
    "#     points = []\n",
    "#     for i in range(100):\n",
    "#         points.append([random.uniform(0.0, 20.0), random.uniform(0.0, 20.0), random.uniform(0.0, 20.0)])\n",
    "\n",
    "#     clusters = dbscan(points, epsilon, min_pts, debug=True)\n",
    "#     print('\\n========== Results of Clustering =============')\n",
    "#     for cluster, members in clusters.items():\n",
    "#         print('\\n--------Cluster %d---------' % cluster)\n",
    "#         for point in members:\n",
    "#             print(point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.spatial.kdtree import KDTree\n",
    "%%time\n",
    "\n",
    "# Build the KD Tree\n",
    "tree = KDTree(xyz)\n",
    "# This should do the same as the FLANN example above, though it might\n",
    "# be a little slower.\n",
    "tree.query(xyz[14966635,], k = eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz[14966635,]==init_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13500.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
